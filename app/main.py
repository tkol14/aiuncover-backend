from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from PIL import Image, ImageOps, ImageChops
import io, re, json
import numpy as np
import exifread
import os
import itertools
from collections import Counter
import cv2 # –î–æ–¥–∞—î–º–æ OpenCV –¥–ª—è —Ä–æ–∑—à–∏—Ä–µ–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É —à—É–º—É, —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–æ

# –Ø–∫—â–æ cv2 –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –µ–º—É–ª—è—Ü—ñ—é
try:
    _ = cv2.Laplacian
except NameError:
    print("Warning: OpenCV (cv2) not found. Falling back to NumPy/PIL for image processing.")
    
# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è FastAPI ---

app = FastAPI(title="AIUncover API", version="1.4.0 - Ultimate", debug=os.environ.get("DEBUG", "False").lower() == "true")

ALLOWED_ORIGINS = [
    "https://aiuncover.net",
    "https://www.aiuncover.net",
    "https://aiuncover-backend-production.up.railway.app",
    "https://api.aiuncover.net",
    "http://localhost:3000"
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

class AnalyzeResponse(BaseModel):
    prob_ai: float
    explanations: list[str]
    checks: dict

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏ ---

AI_TOOL_HINTS = [
    "stable diffusion", "stablediffusion", "sdxl", "novelai",
    "midjourney", "dall-e", "dalle", "leonardo", "flux", "playground",
    "firefly", "adobe firefly", "cf ai", "canva ai", "ideogram", "pollinations",
    "dreamstudio", "getimg.ai", "artbreeder", "pika labs", "runway", "gen-1", "gen-2",
    "aigenerated", "ai generated"
]

COMMON_AI_SIZES = {256, 384, 448, 512, 576, 640, 704, 768, 896, 960, 1024, 1152, 1280, 1536, 1792, 2048}
UNCOMMON_RATIOS = {
    (1, 1), (4, 3), (3, 4), (16, 9), (9, 16), (3, 2), (2, 3), (5, 4), (4, 5)
}

# --- –£—Ç–∏–ª—ñ—Ç–∏ ---

def gcd(a, b):
    while b:
        a, b = b, a % b
    return a

def load_image(raw: bytes):
    bio = io.BytesIO(raw)
    img = Image.open(bio)
    img.load()
    return img

# --- –ú–æ–¥—É–ª—ñ –ü–µ—Ä–µ–≤—ñ—Ä–æ–∫ ---

def read_exif_hints(raw: bytes):
    # (–§—É–Ω–∫—Ü—ñ—è –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è —è–∫ —É –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–º—É –≤–∞—Ä—ñ–∞–Ω—Ç—ñ)
    hints = []
    has_exif = False
    ai_tool_found = False
    try:
        tags = exifread.process_file(io.BytesIO(raw), details=False)
        if tags:
            has_exif = True
            text = " ".join([str(v) for v in tags.values()]).lower()
            if any(h in text for h in AI_TOOL_HINTS):
                hints.append("üö© EXIF/XMP –º—ñ—Å—Ç–∏—Ç—å –∑–≥–∞–¥–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ñ–≤ –®–Ü")
                ai_tool_found = True
        else:
            hints.append("üìù EXIF –≤—ñ–¥—Å—É—Ç–Ω—ñ–π (—á–∞—Å—Ç–∏–π –≤–∏–ø–∞–¥–æ–∫ –¥–ª—è –®–Ü)")
    except Exception:
        hints.append("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ EXIF")
    return has_exif, ai_tool_found, hints

def png_metadata_check(img: Image.Image, fmt: str):
    # (–§—É–Ω–∫—Ü—ñ—è –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è —è–∫ —É –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–º—É –≤–∞—Ä—ñ–∞–Ω—Ç—ñ)
    reasons = []
    ai_prompt_found = False
    if fmt == "PNG":
        try:
            metadata = img.info
            text = json.dumps(metadata).lower()
            
            if any(h in text for h in AI_TOOL_HINTS) or "prompt" in text or "parameters" in text:
                reasons.append("üö© PNG –º–µ—Ç–∞–¥–∞–Ω—ñ (tEXt) –º—ñ—Å—Ç—è—Ç—å –ø—ñ–¥–∫–∞–∑–∫–∏/–ø—Ä–æ–º–ø—Ç –®–Ü")
                ai_prompt_found = True
            elif "software" in metadata and any(h in metadata["software"].lower() for h in AI_TOOL_HINTS):
                reasons.append(f"üö© PNG –º–µ—Ç–∞–¥–∞–Ω—ñ: —É –ø–æ–ª—ñ 'Software' –∑–Ω–∞–π–¥–µ–Ω–æ –®–Ü-—ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç")

        except Exception:
            pass # –Ü–≥–Ω–æ—Ä—É—î–º–æ –ø–æ–º–∏–ª–∫–∏
    return ai_prompt_found, reasons

def size_checks(img: Image.Image):
    # (–§—É–Ω–∫—Ü—ñ—è –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è —è–∫ —É –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–º—É –≤–∞—Ä—ñ–∞–Ω—Ç—ñ)
    w, h = img.size
    reasons = []
    flags = {}
    
    mul_64 = (w % 64 == 0) and (h % 64 == 0)
    mul_8 = (w % 8 == 0) and (h % 8 == 0)
    square_common = (w == h) and (w in COMMON_AI_SIZES)
    
    g = gcd(w, h)
    ratio = (w // g, h // g)
    is_uncommon_ratio = ratio not in UNCOMMON_RATIOS and max(w, h) >= 512
    
    if mul_64:
        reasons.append("üìè –†–æ–∑–º—ñ—Ä–∏ –∫—Ä–∞—Ç–Ω—ñ 64 (—Å–∏–ª—å–Ω–∞ –æ–∑–Ω–∞–∫–∞ Stable Diffusion, SDXL)")
    elif mul_8:
        reasons.append("üìè –†–æ–∑–º—ñ—Ä–∏ –∫—Ä–∞—Ç–Ω—ñ 8 (—Å–ª–∞–±–∫–∞ –æ–∑–Ω–∞–∫–∞)")
        
    if square_common:
        reasons.append(f"üñºÔ∏è –ö–≤–∞–¥—Ä–∞—Ç–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç {w}√ó{h}, —Ç–∏–ø–æ–≤–∏–π –¥–ª—è –®–Ü-–º–æ–¥–µ–ª–µ–π")
        
    if is_uncommon_ratio and (w not in COMMON_AI_SIZES and h not in COMMON_AI_SIZES):
        reasons.append(f"üìê –ù–µ—Ç–∏–ø–æ–≤–∞ —á–∏ –¥—É–∂–µ –≤–∏—Å–æ–∫–∞/–Ω–∏–∑—å–∫–∞ –ø—Ä–æ–ø–æ—Ä—Ü—ñ—è {ratio[0]}:{ratio[1]} –¥–ª—è —Ñ–æ—Ç–æ")
        
    flags["mul64"] = mul_64
    flags["square_common"] = square_common
    flags["is_uncommon_ratio"] = is_uncommon_ratio
    flags["size"] = (w, h)
    return flags, reasons

def alpha_channel_weird(img: Image.Image, fmt: str):
    # (–§—É–Ω–∫—Ü—ñ—è –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è —è–∫ —É –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–º—É –≤–∞—Ä—ñ–∞–Ω—Ç—ñ)
    has_alpha = img.mode in ("LA", "RGBA", "P", "PA")
    if fmt == "JPEG" and has_alpha:
        return True, "‚ö†Ô∏è JPEG –∑ –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–æ–º ‚Äî –Ω–µ—Ç–∏–ø–æ–≤–æ –¥–ª—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ—ñ—ó"
    return False, None

def high_freq_heuristic(img: Image.Image):
    # (–§—É–Ω–∫—Ü—ñ—è –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è —è–∫ —É –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–º—É –≤–∞—Ä—ñ–∞–Ω—Ç—ñ)
    gray = ImageOps.grayscale(img)
    gray_small = gray.resize((256, int(256 * gray.height / gray.width)), Image.Resampling.LANCZOS) if gray.width > 256 else gray
    arr = np.asarray(gray_small, dtype=np.float32) / 255.0

    k = np.array([[0, 1, 0],
                  [1,-4, 1],
                  [0, 1, 0]], dtype=np.float32)
    
    pad_width = 1
    arr_padded = np.pad(arr, pad_width, mode='edge')
    lap = np.abs(np.array([[np.sum(arr_padded[i:i+3, j:j+3] * k) for j in range(arr.shape[1])] for i in range(arr.shape[0])]))

    lap_var = float(np.var(lap))

    f = np.fft.fft2(arr)
    fshift = np.fft.fftshift(f)
    mag = np.abs(fshift)
    h, w = mag.shape
    cy, cx = h//2, w//2
    r = min(cy, cx)
    
    low = mag[cy-r//4:cy+r//4, cx-r//4:cx+r//4].sum() + 1e-6
    high = mag.sum() - low
    high_ratio = float(high / (high + low))

    ai_like = (lap_var < 0.0003 and high_ratio > 0.55)
    expl = f"üî¨ –õ–æ–∫–∞–ª—å–Ω–∞ —Ä—ñ–∑–∫—ñ—Å—Ç—å (var Laplacian={lap_var:.4f}), —á–∞—Å—Ç–æ—Ç–Ω–µ –Ω–∞—Å–∏—á–µ–Ω–Ω—è={high_ratio:.2f}"
    
    if ai_like:
        expl = "üß† –°–∏–Ω—Ç–µ—Ç–∏—á–Ω–∞ —Ç–µ–∫—Å—Ç—É—Ä–∞: –¥—É–∂–µ –Ω–∏–∑—å–∫–∞ –ª–æ–∫–∞–ª—å–Ω–∞ —Ä—ñ–∑–∫—ñ—Å—Ç—å (Laplacian Var) —Ç–∞ –≤–∏—Å–æ–∫–∞ —á–∞—Å—Ç–æ—Ç–Ω–∞ –µ–Ω–µ—Ä–≥—ñ—è ('–ø–ª–∞—Å—Ç–º–∞—Å–æ–≤—ñ—Å—Ç—å')"
        
    return ai_like, expl, {"lap_var": lap_var, "high_ratio": high_ratio}

def jpeg_quant_hint(img: Image.Image, fmt: str):
    # (–§—É–Ω–∫—Ü—ñ—è –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è —è–∫ —É –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–º—É –≤–∞—Ä—ñ–∞–Ω—Ç—ñ)
    try:
        if fmt == "JPEG" and hasattr(img, "quantization") and img.quantization:
            q = img.quantization
            if len(q) <= 2 and all(len(v) == 64 for v in q.values()):
                return False, None
            else:
                return True, "üí° –ù–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ñ JPEG quantization tables (—Å–ª–∞–±–∫–∞ –æ–∑–Ω–∞–∫–∞, –º–æ–∂–µ –±—É—Ç–∏ —Ä–µ-–∫–æ–º–ø—Ä–µ—Å—ñ—è)"
    except Exception:
        pass
    return False, None

def jpeg_artifact_hint(img: Image.Image, fmt: str):
    # (–§—É–Ω–∫—Ü—ñ—è –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è —è–∫ —É –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–º—É –≤–∞—Ä—ñ–∞–Ω—Ç—ñ)
    if fmt == "JPEG" and img.mode in ("RGB", "L"):
        try:
            temp_io = io.BytesIO()
            img.save(temp_io, format="JPEG", quality=95)
            re_compressed = Image.open(temp_io)
            
            diff = ImageChops.difference(img, re_compressed)
            diff_gray = ImageOps.grayscale(diff)
            arr = np.asarray(diff_gray, dtype=np.float32)
            
            std_dev = np.std(arr)
            mean_abs_dev = np.mean(np.abs(arr))
            
            is_low_artifact = (std_dev < 10.0 and mean_abs_dev < 5.0)
            
            if is_low_artifact:
                return True, f"üñºÔ∏è –î—É–∂–µ –Ω–∏–∑—å–∫–∏–π —Ä—ñ–≤–µ–Ω—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ñ–≤ (STD={std_dev:.2f}) –ø—ñ—Å–ª—è —Ä–µ-–∫–æ–º–ø—Ä–µ—Å—ñ—ó (–º–æ–∂–µ –±—É—Ç–∏ –ø–µ—Ä—à–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –®–Ü)"
                
        except Exception:
            pass
    return False, None

def noise_analysis(img: Image.Image):
    """
    –ê–Ω–∞–ª—ñ–∑ —à—É–º—É:
    1. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ *–≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å* —à—É–º—É, —Ç–∏–ø–æ–≤—É –¥–ª—è —ñ–¥–µ–∞–ª—å–Ω–∏—Ö –®–Ü-–∑–æ–±—Ä–∞–∂–µ–Ω—å.
    2. –Ø–∫—â–æ —î OpenCV: –í–∏–¥—ñ–ª–µ–Ω–Ω—è —à—É–º—É –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –≤–µ–π–≤–ª–µ—Ç-—Ñ—ñ–ª—å—Ç—Ä—ñ–≤ –∞–±–æ –≤–∏—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–∏—Ö —Ñ—ñ–ª—å—Ç—Ä—ñ–≤.
    """
    
    # 1. –°–ø—Ä–æ—â–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —à—É–º—É (—è–∫—â–æ –Ω–µ–º–∞—î CV2):
    # –®—É–∫–∞—î–º–æ –æ–¥–Ω–æ—Ä—ñ–¥–Ω—ñ –¥—ñ–ª—è–Ω–∫–∏ —ñ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —ó—Ö–Ω—î —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è.
    gray = ImageOps.grayscale(img)
    arr = np.asarray(gray, dtype=np.float32)
    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤–∏—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–∏–π —Ñ—ñ–ª—å—Ç—Ä (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –õ–∞–ø–ª–∞—Å—ñ–∞–Ω)
    # –ó–Ω–æ–≤—É –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ LapVar —è–∫ –ø—Ä–æ–∫—Å—ñ.
    try:
        if 'cv2' in globals() and hasattr(cv2, 'Laplacian'):
            arr_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)
            laplacian = cv2.Laplacian(arr_cv, cv2.CV_64F)
            noise_std = np.std(laplacian)
        else:
            # –Ø–∫—â–æ –Ω–µ–º–∞—î cv2, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ LapVar –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó
            _, _, freq_vals = high_freq_heuristic(img)
            noise_std = np.sqrt(freq_vals["lap_var"]) * 100 # –ü—Ä–æ—Å—Ç–æ –º–∞—Å—à—Ç–∞–±—É—î–º–æ

    except Exception:
        # –£ –≤–∏–ø–∞–¥–∫—É –ø–æ–º–∏–ª–∫–∏ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ
        return False, "‚ùå –ü–æ–º–∏–ª–∫–∞ –≤ –∞–Ω–∞–ª—ñ–∑—ñ —à—É–º—É", {"noise_std": -1.0}


    # –ï–≤—Ä–∏—Å—Ç–∏–∫–∞:
    # 1. –ù–∞–¥—Ç–æ –Ω–∏–∑—å–∫–µ STD —à—É–º—É (–Ω–∏–∂—á–µ 0.05) - –º–æ–∂–µ –≤–∫–∞–∑—É–≤–∞—Ç–∏ –Ω–∞ –∞–≥—Ä–µ—Å–∏–≤–Ω–µ –∑–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è/–≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –ø—Ä–∏—Ä–æ–¥–Ω–æ–≥–æ —à—É–º—É.
    # 2. –ù–µ—Ç–∏–ø–æ–≤—ñ "–±–ª–æ–∫–æ–≤—ñ" —à—É–º–∏. (–°–∫–ª–∞–¥–Ω–æ –±–µ–∑ –ø–æ–≤–Ω–æ—Ü—ñ–Ω–Ω–æ–≥–æ PRNU, –∞–ª–µ –º–æ–∂–Ω–∞ —Å–ø—Ä–æ—Å—Ç–∏—Ç–∏).
    
    ai_too_smooth = noise_std < 5.0 if 'cv2' in globals() and hasattr(cv2, 'Laplacian') else noise_std < 0.015
    
    if ai_too_smooth:
        expl = f"‚ú® –ù–∞–¥—Ç–æ –≥–ª–∞–¥–∫–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: –ù–∞–¥–∑–≤–∏—á–∞–π–Ω–æ –Ω–∏–∑—å–∫–∏–π —Ä—ñ–≤–µ–Ω—å —à—É–º—É/—Ç–µ–∫—Å—Ç—É—Ä–∏ (STD={noise_std:.2f}) ‚Äî –º–æ–∂–µ –±—É—Ç–∏ –æ–∑–Ω–∞–∫–æ—é –®–Ü-–≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∞–±–æ –∞–≥—Ä–µ—Å–∏–≤–Ω–æ–≥–æ Denoising."
        return True, expl, {"noise_std": float(noise_std)}
        
    return False, f"üî¨ –ê–Ω–∞–ª—ñ–∑ —à—É–º—É: STD={noise_std:.2f} (–≤ –º–µ–∂–∞—Ö –Ω–æ—Ä–º–∏)", {"noise_std": float(noise_std)}


def color_statistic_check(img: Image.Image):
    """
    –ê–Ω–∞–ª—ñ–∑ –∫–æ–ª—ñ—Ä–Ω–æ—ó —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:
    1. –ü–µ—Ä–µ–Ω–∞—Å–∏—á–µ–Ω—ñ—Å—Ç—å (—Ç–∏–ø–æ–≤–∞ –¥–ª—è –¥–µ—è–∫–∏—Ö –®–Ü).
    2. –û–±–º–µ–∂–µ–Ω–∞/–Ω–µ–ø—Ä–∏—Ä–æ–¥–Ω–∞ –ø–∞–ª—ñ—Ç—Ä–∞.
    """
    
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ HSV (–≤—ñ–¥—Ç—ñ–Ω–æ–∫, –Ω–∞—Å–∏—á–µ–Ω—ñ—Å—Ç—å, —è—Å–∫—Ä–∞–≤—ñ—Å—Ç—å)
    try:
        hsv_img = img.convert("HSV")
        hsv_arr = np.asarray(hsv_img, dtype=np.float32) / 255.0
    except Exception:
        return False, "‚ùå –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó –≤ HSV", {}
        
    # –ê–Ω–∞–ª—ñ–∑ –Ω–∞—Å–∏—á–µ–Ω–æ—Å—Ç—ñ (Saturation)
    S = hsv_arr[:, :, 1]
    mean_S = np.mean(S)
    
    # 1. –ü–µ—Ä–µ–Ω–∞—Å–∏—á–µ–Ω—ñ—Å—Ç—å: –®–Ü —á–∞—Å—Ç–æ –≥–µ–Ω–µ—Ä—É—î –∑–∞–Ω–∞–¥—Ç–æ —è—Å–∫—Ä–∞–≤—ñ/–Ω–∞—Å–∏—á–µ–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.
    is_oversaturated = mean_S > 0.60
    
    # 2. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ "—á–∏—Å—Ç—ñ" –∫–æ–ª—å–æ—Ä–∏ (—è–∫—â–æ –±—ñ–ª—å—à—ñ—Å—Ç—å –ø—ñ–∫—Å–µ–ª—ñ–≤ –º–∞—î S~1.0)
    high_S_count = np.sum(S > 0.95)
    total_pixels = S.size
    high_S_ratio = high_S_count / total_pixels
    
    is_cartoon_like = high_S_ratio > 0.05
    
    reasons = []
    
    if is_oversaturated:
        reasons.append(f"üåà –í–∏—Å–æ–∫–∞ —Å–µ—Ä–µ–¥–Ω—è –Ω–∞—Å–∏—á–µ–Ω—ñ—Å—Ç—å ({mean_S:.2f}) ‚Äî —Ç–∏–ø–æ–≤–æ –¥–ª—è –¥–µ—è–∫–∏—Ö –®–Ü")
        
    if is_cartoon_like:
        reasons.append(f"üé® –ë–∞–≥–∞—Ç–æ '—á–∏—Å—Ç–∏—Ö' –∫–æ–ª—å–æ—Ä—ñ–≤ ({high_S_ratio:.2%}) ‚Äî –º–æ–∂–µ –≤–∫–∞–∑—É–≤–∞—Ç–∏ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—É/–º—É–ª—å—Ç—è—à–Ω—É –≥–∞–º—É")

    ai_like = is_oversaturated or is_cartoon_like
    
    return ai_like, reasons, {"mean_s": float(mean_S), "high_s_ratio": float(high_S_ratio)}


# --- –ï–Ω–¥–ø–æ—ñ–Ω—Ç–∏ FastAPI ---

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/analyze/image", response_model=AnalyzeResponse)
async def analyze_image(file: UploadFile = File(...)):
    raw = await file.read()
    if not raw:
        raise HTTPException(400, "–ü–æ—Ä–æ–∂–Ω—ñ–π —Ñ–∞–π–ª")

    explanations = []
    checks = {}

    # 1) EXIF/XMP
    has_exif, ai_tool_found_exif, hints = read_exif_hints(raw)
    explanations += hints
    checks["has_exif"] = has_exif
    checks["ai_tool_found_exif"] = ai_tool_found_exif
    
    # 2) –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    try:
        img = load_image(raw)
    except Exception:
        explanations.append("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è")
        return AnalyzeResponse(prob_ai=0.8, explanations=explanations, checks={"open_error": True})

    fmt = (img.format or "").upper()
    checks["format"] = fmt

    # 3) PNG –º–µ—Ç–∞–¥–∞–Ω—ñ
    ai_found_png, png_reasons = png_metadata_check(img, fmt)
    checks["ai_found_png_metadata"] = ai_found_png
    explanations += png_reasons
    
    # 4) –†–æ–∑–º—ñ—Ä–∏ —Ç–∞ –ø—Ä–æ–ø–æ—Ä—Ü—ñ—ó
    size_flags, size_reasons = size_checks(img)
    checks.update(size_flags)
    explanations += size_reasons

    # 5) –ê–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª
    weird_alpha, alpha_reason = alpha_channel_weird(img, fmt)
    checks["weird_alpha"] = weird_alpha
    if alpha_reason:
        explanations.append(alpha_reason)

    # 6) –ü—Ä–æ—Å—Ç–∞ —á–∞—Å—Ç–æ—Ç–Ω–∞ –µ–≤—Ä–∏—Å—Ç–∏–∫–∞ (–ø–ª–∞—Å—Ç–º–∞—Å–æ–≤—ñ—Å—Ç—å)
    ai_like_freq, freq_expl, freq_vals = high_freq_heuristic(img)
    checks["ai_like_freq"] = ai_like_freq
    checks["freq"] = freq_vals
    explanations.append(freq_expl)

    # 7) JPEG quantization
    q_hint, q_reason = jpeg_quant_hint(img, fmt)
    checks["jpeg_quant_weird"] = q_hint
    if q_reason:
        explanations.append(q_reason)

    # 8) –ê—Ä—Ç–µ—Ñ–∞–∫—Ç–∏ JPEG (–µ–≤—Ä–∏—Å—Ç–∏–∫–∞)
    low_artifact_hint, artifact_reason = jpeg_artifact_hint(img, fmt)
    checks["low_artifact_hint"] = low_artifact_hint
    if artifact_reason:
        explanations.append(artifact_reason)
        
    # 9) –ê–Ω–∞–ª—ñ–∑ —à—É–º—É (NEW)
    ai_too_smooth, noise_expl, noise_vals = noise_analysis(img)
    checks["ai_too_smooth"] = ai_too_smooth
    checks["noise"] = noise_vals
    explanations.append(noise_expl)
    
    # 10) –ê–Ω–∞–ª—ñ–∑ –∫–æ–ª—ñ—Ä–Ω–æ—ó —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (NEW)
    ai_color_weird, color_reasons, color_vals = color_statistic_check(img)
    checks["ai_color_weird"] = ai_color_weird
    checks["color_stats"] = color_vals
    explanations += color_reasons
    
    # ---- –ó–≤–∞–∂—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫ ----
    score = 0.0
    
    # –ù–∞–π—Å–∏–ª—å–Ω—ñ—à—ñ –æ–∑–Ω–∞–∫–∏
    if ai_tool_found_exif or ai_found_png: score += 0.40
    
    # –°–∏–ª—å–Ω—ñ –æ–∑–Ω–∞–∫–∏
    if not has_exif and not ai_found_png and fmt == "JPEG": score += 0.15
    if size_flags["mul64"]:               score += 0.20
    if size_flags["square_common"]:       score += 0.15
    
    # –ü–æ–º—ñ—Ä–Ω—ñ/–°–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ –æ–∑–Ω–∞–∫–∏
    if weird_alpha:                       score += 0.10
    if ai_like_freq:                      score += 0.20 # –ü–ª–∞—Å—Ç–º–∞—Å–æ–≤—ñ—Å—Ç—å
    if low_artifact_hint:                 score += 0.10 # –ß–∏—Å—Ç–µ –ø–µ—Ä—à–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
    if ai_too_smooth:                     score += 0.15 # –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å —à—É–º—É
    if ai_color_weird:                    score += 0.10 # –ù–µ–ø—Ä–∏—Ä–æ–¥–Ω–∞ –≥–∞–º–∞/–Ω–∞—Å–∏—á–µ–Ω—ñ—Å—Ç—å

    # –°–ª–∞–±–∫—ñ –æ–∑–Ω–∞–∫–∏
    if size_flags["is_uncommon_ratio"]:   score += 0.05
    if q_hint:                            score += 0.05
    
    # –ü–æ—Ç–æ–ª–æ–∫ —ñ –ø—ñ–¥–ª–æ–≥–∞
    prob_ai = float(max(0.0, min(1.0, score)))

    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–ª—è —Ä–æ–∑–º—ñ—Ä—ñ–≤ (—è–∫—â–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥—É–∂–µ –º–∞–ª–µ, –¥–æ–≤—ñ—Ä–∞ –¥–æ –∞–Ω–∞–ª—ñ–∑—É –Ω–∏–∂—á–∞)
    w, h = size_flags["size"]
    max_dim = max(w, h)
    
    if max_dim < 384:
        prob_ai = min(1.0, prob_ai + 0.05)

    if max_dim > 2048 and not ai_tool_found_exif:
        prob_ai = max(0.0, prob_ai - 0.10) 


    return AnalyzeResponse(
        prob_ai=round(prob_ai, 2),
        explanations=explanations or ["‚úÖ –û–∑–Ω–∞–∫ –®–Ü –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ —è–≤–Ω–∏—Ö (–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤–∏–≥–ª—è–¥–∞—î —è–∫ –∑–≤–∏—á–∞–π–Ω–µ —Ñ–æ—Ç–æ)"],
        checks=checks
    )